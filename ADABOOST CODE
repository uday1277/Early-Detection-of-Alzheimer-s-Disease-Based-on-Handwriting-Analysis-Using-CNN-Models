import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# 1. Load your dataset
file_path = '/content/data (3).csv'  # Update with your actual file path
df = pd.read_csv(file_path)

# 2. Preprocess the Data
# Drop non-numeric columns like IDs if they exist
if 'id' in df.columns or 'ID' in df.columns or 'id_1' in df.columns:
    df = df.drop(columns=['id', 'ID', 'id_1'], errors='ignore')

# Split features (X) and target (y)
X = df.drop(columns=['class'])  # Replace 'target' with your actual target column name
y = df['class']

# Encode target labels into integers
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_encoded, test_size=0.2, random_state=42
)

# 4. Optimized AdaBoost Model
base_model = DecisionTreeClassifier(max_depth=3)  # Increased depth for better learning
model = AdaBoostClassifier(estimator=base_model, n_estimators=200, learning_rate=0.8, random_state=42)

# 5. Train the Model
model.fit(X_train, y_train)

# 6. Predict on Test Data
y_pred = model.predict(X_test)

# 7. Evaluate the Model
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.4f}")

# 8. Manual Accuracy Calculation
manual_accuracy = accuracy_score(y_test, y_pred)
print(f"Manual Test Accuracy: {manual_accuracy:.4f}")
